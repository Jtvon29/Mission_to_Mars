{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize browser\n",
    "def init_Browser():\n",
    "    # @NOTE: Replace the path with your actual path to the chromedriver\n",
    "    executable_path = {\"executable_path\": \"Resources/chromedriver.exe\"}\n",
    "    return Browser(\"chrome\", **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to scrape the Nasa website\n",
    "def scrape_nasa():\n",
    "    \n",
    "    # Initialize the browser\n",
    "    browser = init_Browser()\n",
    "    # Visit the Nasa website\n",
    "    nasa_url = \"https://mars.nasa.gov/news/?page=0&per_page=40&order=publish_date+desc%2Ccreated_at+desc&search=&category=19%2C165%2C184%2C204&blank_scope=Latest\"\n",
    "    browser.visit(nasa_url)\n",
    "    # Scrape the page into soup\n",
    "    nasa_html = browser.html\n",
    "    nasa_soup = BeautifulSoup(nasa_html, 'html.parser')\n",
    "    # Find the most recent article title and paragraph text\n",
    "    Article = nasa_soup.find(\"li\", class_=\"slide\")\n",
    "    # Get the title of the article\n",
    "    Article_title = Article.find(\"div\", class_=\"content_title\").text\n",
    "    # Get the paragraph text\n",
    "    Paragraph_text = Article.find(\"div\", class_=\"article_teaser_body\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_image():\n",
    "    \n",
    "    # Scrape mars image\n",
    "    #Visit the website\n",
    "    url = 'https://www.jpl.nasa.gov/spaceimages/?search=&category=Mars'\n",
    "    browser.visit(url)\n",
    "    # Navigate to the Full size image\n",
    "    browser.click_link_by_partial_text('FULL IMAGE')\n",
    "    browser.click_link_by_partial_text('more info')\n",
    "    #Scrape the page into soup\n",
    "    image_html = browser.html\n",
    "    image_soup = BeautifulSoup(image_html, 'htm.parser')\n",
    "    #Collect the path and paste to the new url\n",
    "    image_path = image_soup.find('figure', class_='lede').a['href']\n",
    "    featured_image_url = 'https://www.jpl.nasa.gov' + image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_tweets():\n",
    "    \n",
    "    #Scrape weather from tweets\n",
    "    #Visit the website\n",
    "    twitter_url = 'https://twitter.com/marswxreport?lang=en'\n",
    "    browser.visit(twitter_url)\n",
    "    #Scrape the page using soup\n",
    "    twitter_html = browser.html\n",
    "    twitter_soup = BeautifulSoup(twitter_html,'html.parser')\n",
    "    #Get the most recent tweet about the weather\n",
    "    mars_weather = twitter_soup.find('p', class_='TweetTextSize TweetTextSize--normal.js-tweet-text.tweet-text').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_table():\n",
    "    \n",
    "    # Scrape data table from website\n",
    "    #Visit the website\n",
    "    table_url = 'https://space-facts.com/mars/'\n",
    "    #Read the table in using read_html\n",
    "    table = pd.read_html(table_url)\n",
    "    #Make it into a datframe\n",
    "    df = table[0]\n",
    "    #Convert it back into html\n",
    "    html_table = df.to_html()\n",
    "    html_table.replace('\\n', '')\n",
    "    #Save it as a file\n",
    "    Data_table = df.to_html('Resources/table.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scrape_hemi():\n",
    "    \n",
    "    # Scrape the hemisphere images of mars\n",
    "    #Visit the website\n",
    "    hemi_main_url = 'https://astrogeology.usgs.gov/search/results?q=hemisphere+enhanced&k1=target&v1=Mars'\n",
    "    browser.visit(hemi_main_url)\n",
    "    #Scrape the page into soup\n",
    "    hemi_main_html = browser.html\n",
    "    hemi_main_soup = BeautifulSoup(hemi_main_html, 'html.parser')\n",
    "    #Find the path to the full size images\n",
    "    first = hemi_main_soup.find('div', class_='collapsible results')\n",
    "    second = first.find_all('div', class_='description')\n",
    "    #Create an empty list to hold the images\n",
    "    Hemisphere_images = []\n",
    "    #create a loop to find the images of the hemispheres in each link\n",
    "    for x in second:\n",
    "        #go to the link\n",
    "        title = x.a.h3.text\n",
    "        link = 'https://astrogeology.usgs.gov' + x.a['href']\n",
    "        browser.visit(link)\n",
    "        #Scrape the page into soup\n",
    "        hemi_html = browser.html\n",
    "        hemi_soup = BeautifulSoup(hemi_html, 'html.parser')\n",
    "        #find the path of the fullsize image\n",
    "        image_link = hemi_soup.find('div', class_='downloads').find('li').a['href']\n",
    "        #Create dictioanry to hold the urls\n",
    "        hemi_dict = {}\n",
    "        hemi_dict['title'] = title\n",
    "        hemi_dict['link'] = link\n",
    "        Hemisphere_images.append(hemi_dict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
